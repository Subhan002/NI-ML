{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f810a5a6",
   "metadata": {},
   "source": [
    "# Network Intrusion Data Analysis\n",
    "The following dataset analysis is completed with the goal of creating a model on detecting possible network anomalies\n",
    "We will be performing this analysis on the following dataset (https://www.kaggle.com/datasets/sampadab17/network-intrusion-detection/data)\n",
    "This dataset contains TCP/IP dump data for a number of simulated network intrusions on a network setup like a typical AirForce LAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f80d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a005d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9c4b25",
   "metadata": {},
   "source": [
    "### Data Pre Processing\n",
    "Our dataset contains 42 columns describing data collected from networks of different types\n",
    "We will be examining the data to learn about the different columns and find any redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f5b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test data from the csv\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "train_data.head() # display the first 5 data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce66577",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "test_data.head() # display the first 5 data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8af8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View different data types in the train data\n",
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1739da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.rename(columns={'class': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c874d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View datatypes for the test data\n",
    "test_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce5a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View unique values for columns with object data types\n",
    "train_data.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e8ed64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of missing values in the train data\n",
    "total = train_data.shape[0]\n",
    "missing_columns = [col for col in train_data.columns if train_data[col].isnull().sum() > 0]\n",
    "for col in missing_columns:\n",
    "    null_count = train_data[col].isnull().sum()\n",
    "    per = (null_count/total) * 100\n",
    "    print(f\"{col}: {null_count} ({round(per, 3)}%)\")\n",
    "\n",
    "# There are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2685485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if there are any duplicate rows in the train data\n",
    "print(f\"Number of duplicate rows: {train_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in num_outbound_cmds column\n",
    "train_data.num_outbound_cmds.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6346e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column 'num_outbound_cmds' has only one unique value, so we can drop it\n",
    "train_data.drop(['num_outbound_cmds'], axis=1, inplace=True)\n",
    "test_data.drop(['num_outbound_cmds'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae7749",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='label', data=train_data)\n",
    "plt.title('Distribution of Classes')\n",
    "plt.show()\n",
    "# here we can see that roughly 12 thousand samples are 0, these data samples are classified as network intrusion\n",
    "# we see that almost 14 thousand samples are not classified as network intrusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0cbd8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=['label'])  # Features\n",
    "y_train = train_data['label']  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dbd989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "for column in X_train.select_dtypes(include=['object']).columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    X_train[column] = label_encoders[column].fit_transform(X_train[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f81058e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1493256",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3e8026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9a209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25d79ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_val, val_predictions), annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix - Validation Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b330c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data\n",
    "for column, encoder in label_encoders.items():\n",
    "    X_test[column] = encoder.transform(X_test[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c147d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3767803a",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
